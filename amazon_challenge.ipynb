{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_challenge2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXeSV0BxFgzV"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import chi2\n",
        "import re\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from scipy.stats import loguniform\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTIbeVO_F-_P"
      },
      "source": [
        "path = \"drive/MyDrive/Amazon ML Challenge/test.csv\"\n",
        "df_test = pd.read_csv(path, escapechar = \"\\\\\", quoting = csv.QUOTE_NONE)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcxsyP5EF6sL"
      },
      "source": [
        "path = \"drive/MyDrive/Amazon ML Challenge/train.csv\"\n",
        "df_train = pd.read_csv(path, escapechar = \"\\\\\", quoting = csv.QUOTE_NONE)\n",
        "df_train = df_train.dropna()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzMUqgNDF6Y6"
      },
      "source": [
        "punctuation_signs = list(\"?:!.,;\")\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('stopwords')\n",
        "stop_words = list(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_o0rqEcF5-V"
      },
      "source": [
        "df_train['Title'] = df_train['TITLE'].str.replace(\"\\r\", \" \")\n",
        "df_train['Title'] = df_train['Title'].str.replace(\"\\n\", \" \")\n",
        "df_train['Title'] = df_train['Title'].str.replace(\"    \", \" \")\n",
        "df_train['Title'] = df_train['Title'].str.replace('\"', '')\n",
        "df_train['Title'] = df_train['Title'].str.lower()\n",
        "for punct_sign in punctuation_signs:\n",
        "  df_train['Title'] = df_train['Title'].str.replace(punct_sign, '')\n",
        "df_train['Title'] = df_train['Title'].str.replace(\"'s\", \"\") "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j40pBiAnF5qI"
      },
      "source": [
        "final_cols = [\"Title\", \"BROWSE_NODE_ID\"]\n",
        "df_train = df_train[final_cols]\n",
        "df_train = df_train.iloc[:200000, :]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH4N1b6tF49U"
      },
      "source": [
        "df_test['Title'] = df_test['TITLE'].str.replace(\"\\r\", \" \")\n",
        "df_test['Title'] = df_test['Title'].str.replace(\"\\n\", \" \")\n",
        "df_test['Title'] = df_test['Title'].str.replace(\"    \", \" \")\n",
        "df_test['Title'] = df_test['Title'].str.replace('\"', '')\n",
        "df_test['Title'] = df_test['Title'].str.lower()\n",
        "for punct_sign in punctuation_signs:\n",
        "  df_test['Title'] = df_test['Title'].str.replace(punct_sign, '')\n",
        "df_test['Title'] = df_test['Title'].str.replace(\"'s\", \"\")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEHcaUycF4tx"
      },
      "source": [
        "final_cols = [\"Title\", \"PRODUCT_ID\"]\n",
        "df_test = df_test[final_cols]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haD3hKb7F1au"
      },
      "source": [
        "X_train, X_test, y_train = df_train[\"Title\"], df_test[\"Title\"], df_train[\"BROWSE_NODE_ID\"]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LO0v4a_F2QL"
      },
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=5)\n",
        "X_train_vectors_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_vectors_tfidf = tfidf.transform(X_test)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbrX-W3T2TEX"
      },
      "source": [
        "fig = px.bar(x = X_train_vectors_tfidf, y = y_train, log_y=True, color=[0.0]*len(class_distri[0])) # Logarithmically scaled because large imbalance.\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqR3qxx4avhq"
      },
      "source": [
        "# LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbuGVg9PIF0W"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform as sp_uniform\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "lgb = LGBMClassifier().fit(X_train_vectors_tfidf, y_train)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUcFLnTTJ_pi"
      },
      "source": [
        "y_predict = lgb.predict(X_test_vectors_tfidf)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL3lEJo2aKUk"
      },
      "source": [
        "d = {\"BROWSE_NODE_ID\" : y_predict}\n",
        "df1 = pd.DataFrame(data=d)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwu4jQR6aOZY"
      },
      "source": [
        "df_new = pd.concat([df_test, df1], axis = 1)\n",
        "l = [\"PRODUCT_ID\", \"BROWSE_NODE_ID\"]\n",
        "df_new = df_new[l]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTPQUzmhaODr"
      },
      "source": [
        "df_new.to_csv(\"drive/MyDrive/Amazon ML Challenge/submission_LGBM.csv\", index = False, header = True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVLm32UkaNmD"
      },
      "source": [
        "path = \"drive/MyDrive/Amazon ML Challenge/submission.csv\"\n",
        "df_sub = pd.read_csv(path)\n",
        "df_sub.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD9HXASzam7s"
      },
      "source": [
        "# Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKrx0-hdfsss",
        "outputId": "dad166a0-9577-4870-f088-8a296957e0c4"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPFKKd2BF0IM"
      },
      "source": [
        "lr_tfidf = LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
        "lr_tfidf.fit(X_train_vectors_tfidf, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7OI1SwPGd0L"
      },
      "source": [
        "y_predict = lr_tfidf.predict(X_test_vectors_tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4WujtTXGdhG"
      },
      "source": [
        "d = {\"BROWSE_NODE_ID\" : y_predict}\n",
        "df1 = pd.DataFrame(data=d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Mu7B3dGdP5"
      },
      "source": [
        "df_new = pd.concat([df_test, df1], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW3CXdNLGc8X"
      },
      "source": [
        "l = [\"PRODUCT_ID\", \"BROWSE_NODE_ID\"]\n",
        "df_new = df_new[l]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2p3QWnAGcpA"
      },
      "source": [
        "df_new.to_csv(\"drive/MyDrive/Amazon ML Challenge/submission.csv\", index = False, header = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BqNNJRtGcTd"
      },
      "source": [
        "path = \"drive/MyDrive/Amazon ML Challenge/submission.csv\"\n",
        "df_sub = pd.read_csv(path)\n",
        "df_sub.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}